
<!-- saved from url=(0064)http://azrael.digipen.edu/~mmead/www/Courses/CS280/Analysis.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<link rel="stylesheet" type="text/css" href="./Algorithm Analysis_files/new.css">
<title>Algorithm Analysis</title>
</head>

<body>  
<center><h1>Algorithm Analysis</h1></center>

<blockquote><i>
"Beware of bugs in the above code; I have only proved it correct, not tried it."</i> -- Donald Knuth
</blockquote>

<!--
<hr>
<p>
<a href="Methodology.html">Review of The Software Development Cycle</a>
<p>
-->


<!-- ************************************************************************************************ -->
<!-- ************************************************************************************************ -->
<hr>

<h2>Beginning Analysis</h2>

The point of analyzing algorithms is to be able to say that one algorithm is <i>better</i> than the other.

<ul>
<li>What does it mean to be <i>better</i>?
</li><li>If all algorithms were the same (none are better than any other), we wouldn't be here.
</li><li>Implement the algorithm (in a programming language) and then decide?
</li><li>Design it on paper and then decide?
</li><li>If it's going to run on a computer, which one?
</li><li>Which language will prove to be best? Which compiler?
</li><li>How do we measure? What data do we use?
</li></ul>

<b>Example 1:</b>

Assume that we have an array of random integers and that we wish to find out where <b><i>x</i></b> is in 
the array. When the <b>while</b>
loop ends, <b><i>n</i></b> will be the position of <b><i>x</i></b> in the array.

<!--  <font color="#003399"><i>// Assume that <b><i>x</i></b> is in the array</i></font> -->

<pre class="sourcecode"><code>  <font color="#003399"><i>// Assume a declaration like: <b>int</b> a[SIZE];</i></font>
  <b>int</b> n = 0;
  <b>while</b> (x != a[n])
    n++;</code></pre>

To find the position of <b><i>x</i></b> in the array:
<ul>
<li>What is the <i>least</i> number of iterations?
</li><li>What is the <i>most</i> number of iterations?
</li><li>What is the <i>average</i> number of iterations? (Assume a uniform distribution)
</li><li>What search method did you use to arrive at these numbers?
<!--<li><b>Bonus</b>: How would you create an unsorted array of unique integers? -->
<!-- How about a sorted array? --> 
</li></ul>

<a href="http://azrael.digipen.edu/~mmead/www/Courses/CS280/Analysis-LinearSearch.cpp.html">Simple code example</a>
<p>

Suppose the array was sorted. Now how would you answer these questions:
</p><ul>
<li>What search method would you use?
</li><li>How would the search method affect these questions:
<ul>
<li>What is the <i>least</i> number of iterations?
</li><li>What is the <i>most</i> number of iterations?
<!--<li>What is the <i>average</i> number of iterations?-->
</li></ul>
</li></ul>

Some points to make:
<ul>
<li>The simple linear search method is called a <i>linear-time algorithm</i>. 
(The time is directly proportional to the number of elements.)
</li><li>Compare this with a binary search algorithm. 
</li><li>What property must the array have to use a binary search method? 
</li><li>Binary search is a <i>logarithmic-time algorithm</i>.
</li></ul>

<a href="http://azrael.digipen.edu/~mmead/www/Courses/CS280/Searching.cpp.html">Search code</a>.
<p>


<b>Example 2:</b>

Assume that we have a <i>linked list</i> of random integers and that we wish to find out 
where <b><i>x</i></b> is in the list. When the <b>while</b>
loop ends, <b><i>n</i></b> will be the position of <b><i>x</i></b> in the list.
</p><p>
</p><blockquote>
<table border="0" cellspacing="15" cellpadding="5">
<tbody><tr><th>Assume this struct</th><th>Search code</th></tr>
<tr valign="top">
<td>
<blockquote><pre><b>struct</b> Node
{
  <b>int</b> data;
  Node *next;
};
</pre></blockquote>
</td>
<td>
<!--<font color="#003399"><i>// Assume that <b><i>x</i></b> is in the list</i></font>-->
<blockquote><pre><font color="#003399"><i>// Assume the list has SIZE nodes</i></font>
<b>int</b> n = 0;
Node *node = head; <font color="#003399"><i>// head of the linked list</i></font>
<b>while</b> (node)
{
  n++;
  <b>if</b> (node-&gt;data == x)
    <b>break</b>;
  node = node-&gt;next;
}
</pre></blockquote>
</td>
</tr></tbody></table>
</blockquote>

To find the position of <b><i>x</i></b> in the list:
<ul>
<li>What is the <i>least</i> number of iterations?
</li><li>What is the <i>most</i> number of iterations?
</li><li>What is the <i>average</i> number of iterations?
</li><li>What search method did you use to arrive at these numbers?
</li></ul>

Suppose the list was sorted. Now how would you answer these questions:
<ul>
<li>What search method would you use?
</li><li>How would the search method affect these questions:
<ul>
<li>What is the <i>least</i> number of iterations?
</li><li>What is the <i>most</i> number of iterations?
<!--<li>What is the <i>average</i> number of iterations?-->
</li></ul>
</li></ul>


Analysis points:
<ul>
<li>Informally, we want to figure out the number of steps required to perform the computation.
</li><li>The goal is to write a formula (equation) for the computation time <b><i>in terms of the 
  size of the problem</i></b>.
</li><li>Some parts of the formula are constant. (Constants of proportionality)
</li><li>The <i>growth rate</i> is the part of the formula that <i>varies</i> with the size of the 
  problem. 
</li><li>The <i>dominant</i> term is all that matters to us. We can throw away the rest.
</li><li>The notation is <b>O( )</b>, called any number of things such as "Big Oh", "growth rate", 
  "order of", "proportional to", to
name a few. "Big Oh" is what we'll use.
</li><li> A technical name for the big O notation is <i>worst case asymptotic time complexity</i>.
  (This is the upper-bound on the algorithm.)
  <ul>
    <li>There's also "Big Omega" (&#937;), which is a lower-bound. (We won't concern ourselves
      with that.)</li>
  </ul>
</li></ul>


Let's compare the worst case of the algorithms for searching through an unsorted array and a 
sorted array: 

<blockquote><pre> Number of     Linear    Binary
  elements     search    search
-------------------------------
       10          10       4
      100         100       7
    1,000       1,000      10
   10,000      10,000      14
  100,000     100,000      17
1,000,000   1,000,000      20
</pre></blockquote>

<!--
<blockquote><pre>
	             linear    binary
     n         search    search                    n/2     log<sub>2</sub> n
-------------------------------
       10           5      4
      100          50      7
    1,000         500     10
   10,000       5,000     14
  100,000      50,000     17
1,000,000     500,000     20
</pre></blockquote>
-->
<p>

<!--
<hr>
Quick logarithm review:
<blockquote><pre>
1. log<sub>b</sub> (xy) = log<sub>b</sub> x + log<sub>b</sub> y
2. log<sub>b</sub> (x/y) = log<sub>b</sub> x - log<sub>b</sub> y
3. log<sub>b</sub> (x<sup>k</sup>) = k log<sub>b</sub> x
4. if (y = b<sup>x</sup>) ==> (x = log<sub>b</sub> y)

             log<sub>b</sub> x
5. log<sub>a</sub> x = ---------
             log<sub>b</sub> a

</pre></blockquote>

<blockquote>
      
If 2<sup>x</sup> = 7, what is x? 2<sup>2</sup> = 4 and 2<sup>3</sup> = 8, now what?
<p>
We can take the log of both sides:

<blockquote><pre>
log 2<sup>x</sup> = log 7
</pre></blockquote>

Using rule #3 for the left side we get

<blockquote><pre>
x log 2 = log 7
</pre></blockquote>

Divide by log 2:

<blockquote><pre>
    log 7   1.946
x = ----- = ----- = 2.8075
    log 2   0.693
</pre></blockquote>
    
Note that the logarithm base is irrelevant. It will work with any base.
</blockquote>

-->
</p><p>
</p><hr width="90%">
<p>



</p><h4>New Example:</h4>
Suppose we have 2 algorithms whose running times are described as: (where N is the number 
of elements in the data set)
<ol>
<li>5 N<sup>2</sup> microseconds 
</li><li>50 N lg N microseconds
</li></ol>
Which one is faster? (lg is shorthand for log<sub>2</sub>, a microsecond is 1 millionth of a second). 

<blockquote><pre>     N           5 N<sup>2</sup> microsecs       50 N lg N microsecs
-------------------------------------------------------------
       10     0.0005 sec               0.002 sec  
      100     0.05 sec                  0.03 sec   
    1,000     5 sec                      0.5 sec 
   10,000     500 sec       = 8 min      6.6 sec
  100,000     50,000 sec    = 14 hr       83 sec
1,000,000     5,000,000 sec = 58 days    997 sec = 17 min 
</pre></blockquote>

<p>
</p><hr width="90%">
<p>

</p><p>
Another comparison of two arbitrary algorithms:  (n<sub>0</sub> approx. 31.45)
</p><p>

<img src="./Algorithm Analysis_files/Comparing.gif" width="291" height="268">
</p><p>
<a href="http://azrael.digipen.edu/~mmead/www/Courses/CS280/Comparing-Big.gif">Larger</a> picture.
</p><p>

Suppose we find an algorithm whose runtime is described by: <i>f(n) = n<sup>2</sup> + 2n + 100</i>
</p><p>
Values of the dominant term:

</p><blockquote><pre>    n    |        f(n)              n<sup>2</sup>      n<sup>2</sup>-term as % of total
---------+------------------------------------------------------------
     10  |            220             100        45.455
    100  |         10,300          10,000        97.087
  1,000  |      1,002,100       1,000,000        99.790
 10,000  |    100,020,100     100,000,000        99.980
100,000  | 10,000,200,100  10,000,000,000        99.999
</pre></blockquote>

Now, add a cubic term: <i>f(n) = n<sup>3</sup> + n<sup>2</sup> + 2n + 100</i>
<p>
Values of the dominant term:

<!--
    n    |        f(n)                           n<sup>3</sup>        n<sup>3</sup>-term as % of total
---------+------------------------------------------------------------------------
     10  |                 1,120                   1,000       89.285714
    100  |             1,000,300               1,000,000       99.970009
  1,000  |         1,000,002,100           1,000,000,000       99.999790
 10,000  |     1,000,000,020,100       1,000,000,000,000       99.999998
100,000  | 1,000,000,000,200,100   1,000,000,000,000,000      100.000000
-->


</p><blockquote><pre>    n    |        f(n)                           n<sup>3</sup>        n<sup>3</sup>-term as % of total
---------+-------------------------------------------------------------------------
     10  |                  1,220                   1,000      81.967213
    100  |              1,010,300               1,000,000      98.980501
  1,000  |          1,001,002,100           1,000,000,000      99.899890
 10,000  |      1,000,100,020,100       1,000,000,000,000      99.989999
100,000  |  1,000,010,000,200,100   1,000,000,000,000,000      99.999000
</pre></blockquote>

Now, add an exponential term: <i>f(n) = 2<sup>n</sup> + n<sup>3</sup> + n<sup>2</sup> + 2n + 100</i>
<p>
Values of the dominant term:

</p><blockquote><pre>    n    |        f(n)                  2<sup>n</sup>          2<sup>n</sup>-term as % of total
---------+-------------------------------------------------------------------------
    10   |             2,244               1,024        45.632799
    20   |         1,057,116           1,048,576        99.192142
    30   |     1,073,769,884       1,073,741,824        99.997387
    40   | 1,099,511,693,556   1,099,511,627,776        99.999994
</pre></blockquote>



It quickly becomes apparent why we are only concerned with the dominant term. The lesser terms are 
so insignifcant that they
can be completely ignored. This greatly simplifies the comparisons among different functions.
<p>

</p><hr width="90%">

Common growth rates
<blockquote><pre>O(k)           Constant, (<i>not</i> affected by the size of the data, sometimes written as O(1))
O(lg N)        Logarithmic (usually base 2)
O(N)           Linear (directly proportional to N)
O(N lg N)      No formal name, but just spoken as "N log N" 
O(N<sup>2</sup>)          Quadratic (proportional to square of N)
O(N<sup>3</sup>)          Cubic (proportional to cube of N)
O(N<sup>k</sup>)          Polynomial (proportional to N to the power k)
O(2<sup>N</sup>)          Exponential (proportional to 2 to power of N)
</pre></blockquote>

The growth rate for some common formulas as a function of the size of the problem, N (logarithmic scale)
<p>
<img src="./Algorithm Analysis_files/GrowthFunctions.gif" width="354" height="284">
</p><p>
<a href="http://azrael.digipen.edu/~mmead/www/Courses/CS280/GrowthFunctionsBig.gif">Larger</a> picture.


</p><pre>lgN (lgN)<sup>2</sup>  N<sup>1/2</sup>       N          NlgN        N(lgN)<sup>2</sup>         N<sup>3/2</sup>          N<sup>2</sup>
---------------------------------------------------------------------------------
 3     9      3         <b>10</b>           30            90           30           100
 6    36     10        <b>100</b>          600         3,600        1,000        10,000
 9    81     31      <b>1,000</b>        9,000        81,000       31,000     1,000,000
13   169    100     <b>10,000</b>    1,300,000     1,690,000    1,000,000   100,000,000
16   256    316    <b>100,000</b>    1,600,000    25,600,000   31,600,000    10 billion
19   361  1,000  <b>1,000,000</b>   19,000,000   361,000,000    1 billion    1 trillion
</pre>

<p>
<i>f(n)</i> = (dominant term) + (lesser terms)
<br>
O(<i>f(n)</i>) = O(dominant term + lesser terms) = O(dominant term)
</p><p>
Relationship of growth rates:
</p><blockquote><pre>O(1) &lt; O(lg N) &lt; O(N) &lt; O(N lg N) &lt; O(N<sup>2</sup>) &lt; O(N<sup>3</sup>) &lt; O(2<sup>N</sup>)
</pre></blockquote>

Sometimes you 'll see it written this way:
<blockquote><pre>O(1) = O(lg N) = O(N) = O(N lg N) = O(N<sup>2</sup>) = O(N<sup>3</sup>) = O(2<sup>N</sup>)
</pre></blockquote>

The equals sign "=" does not mean equality, but rather should be read as "is contained in". 
I prefer to use the 
"greater than" and "less than" symbols to avoid confusion.
<p>


</p><p>
</p><hr width="90%">
<p>

Given these rules:
</p><blockquote><pre>O(a) = O(b)                    (a and b are both constants)
O(N + c) = O(N) + O(c) = O(N)  (c is a contant)
O(N) + c = O(N)                (c is a constant)
O(cN) = cO(N) = O(N)           (c is a constant)
</pre></blockquote>

<!--
O(N) + O(M) = O(M) + O(N)
O(N) + O(M) = O(N)             (if M <= N)
-->
Replace the "?" with &lt;, &gt;, or =

<blockquote><pre>1. =  O(6) ? O(12)  
2. =  O(N + 5) ? O(N + 100)
3. &lt;  O(lg N) ? O(N)
4. =  O(N/2) ? O(2N)
5. &lt;  O(N<sup>2</sup> + N) ? O(N<sup>3</sup>)
6. &lt;  O(N lg N + N<sup>3</sup>) ? O(2<sup>N</sup>)
7. =  O(N) + O(lg 2<sup>N</sup>) ? O(N)
8. =  O(lg N) ? O(log<sub>10</sub> N)
9.    O(N/4) ? O(1/N)  What is different about this one?
</pre></blockquote>
<!--8. <  O(2<sup>N</sup>) ? O(5<sup>N</sup>)-->

<p>
Note on #8: Changing the base of the logarithm is a constant factor, so it is
discarded in big-O notation.
</p><p>


<b>Some concrete values:</b> (Assuming 1 microsecond per element)

</p><blockquote><pre>	           Number of elements in the data set
     Time          ----------------------------------
  complexity       N=10           N=20           N=30
------------------------------------------------------------
      N           0.00001 sec    0.00002 sec    0.00003
      N<sup>2</sup>          0.0001 sec     0.0004 sec     0.0009 sec
      N<sup>3</sup>          0.001 sec      0.008 sec      0.027 sec
      N<sup>5</sup>          0.1 sec        3.2 sec       24.3 sec
      2<sup>N</sup>          0.001 sec      1.0 sec       17.9 min
      3<sup>N</sup>          0.59 sec      58 min          6.5 years
</pre></blockquote>

<b>Time to solve very large problems</b> (from Sedgewick page 40)

<blockquote><pre>operations    problem size 1 million        problem size 1 billion
   per       -------------------------------------------------------
 second         N      N lg N     N<sup>2</sup>         N      N lg N     N<sup>2</sup>
--------------------------------------------------------------------
  10<sup>6</sup>        seconds  seconds   weeks      hours     hours   never
  10<sup>9</sup>        instant  instant   hours      seconds  seconds  decades
  10<sup>12</sup>       instant  instant  seconds     instant  instant  weeks
--------------------------------------------------------------------
</pre></blockquote>


<hr>
<p>

<!--
<div class="hidden"><div class="hidden"><div class="hidden"><div class="hidden">
-->

<!-- ************************************************************************************************ -->
<!-- ************************************************************************************************ -->
</p><h4>A (slightly) real world situation</h4>

Each loop below accomplishes the same thing. (<tt>a</tt> is square 2D array)
<ul>
<li>What does the loop do?
</li><li>Which one is easier to read?
</li><li>Which one do you think is more efficient? Why?
</li><li>What is the difference between the <i>best, average,</i> and <i>worst</i> case?
</li><li>Which would you prefer to use in your program? Why?
</li></ul>


<pre class="sourcecode"><code>
<b>void</b> Test1(<b>int</b> n)
{
  <b>for</b> (<b>int</b> i = 1; i &lt;= n; i++)
  {
    <b>for</b> (<b>int</b> j = 1; j &lt;= n; j++)
    {	
      a[i - 1][j - 1] = (i / j) * (j / i);
    }
  }
}

<b>void</b> Test2(<b>int</b> n)
{
  <b>for</b> (<b>int</b> i = 0; i &lt; n; i++)
  {
    <b>for</b> (<b>int</b> j = 0; j &lt; n; j++)
    {
      <b>if</b> (i == j)
        a[i][j] = 1;
      <b>else</b>
        a[i][j] = 0;
    }
  }
}

<b>void</b> Test3(<b>int</b> n)
{
  <b>for</b> (<b>int</b> i = 0; i &lt; n; i++)
  {
    <b>for</b> (<b>int</b> j = 0; j &lt; n; j++)
    {
      a[i][j] = 0;
    }
    a[i][i] = 1;
  }
}
</code></pre>

<ul>
<li>Analyze the loops above and see if your initial reactions were correct.
</li><li>This ignores many real-world factors, such as the hardware capabilities (cache, locality of 
  reference, etc.)
</li><li>External factors are considered <i>constants</i> in this class. 
</li><li>In the Real World<font size="-1"><sup>TM</sup></font>, you can't assume that an algorithm on paper 
  will perform the same on all computers.
</li></ul>

<!--

N^2 mul
N^2 assigns
N^2 divs
-----------
4N^2


N^2 compares
N^2 assigns
-----------
2N^2


N^2 assigns
N assigns
----------
N^2 + N

-->

<p>
Profiling <a href="http://azrael.digipen.edu/~mmead/www/Courses/CS280/Profiling.html">results</a> will show more details.
</p><p>

</p><hr>
<p>

Estimating the growth rate of an algorithm is affected by:

</p><ul>
<!--<li>Sequences-->
<li>Conditionals
</li><li>Function calls
</li><li>Loops (this is the big-ticket item)
</li></ul>

Analyze these code fragments to get the feel for the analysis.
<a href="http://azrael.digipen.edu/~mmead/www/Courses/CS280/BigO-CodeExamples.html">Code fragments</a>
<p>


</p><p>
Consider this loop. Look carefully at the counters. What is the time complexity of these loops?

</p><pre class="sourcecode"><code><b>for</b> (<b>int</b> i = 0; i &lt; N; i++)
{
  <b>for</b> (<b>int</b> j = 0; j &lt; i; j++)
  {	
    [  do something in O(1)    ]
  }
}

<b>for</b> (<b>int</b> i = 0; i &lt; N; i++)
{
  <b>for</b> (<b>int</b> j = i; j &lt; N; j++)
  {	
    [  do something in O(1)    ]
  }
}</code></pre>

In general, a programming construct with <i>k</i> nested loops has performance O(N<sup>k</sup>) 
if the loop counter
is dependent on the size of the problem. This is <i>polynomial</i> growth rate.
<p>

The sum of the integers from 1 to N can be written as:

</p><blockquote><pre>                         N(N + 1)                                                     N(N - 1)
1 + 2 + 3 + 4 ... + N = ---------    or similarly  0 + 1 + 2 + 3 + 4 + ... + N - 1 = ---------
                            2                                                            2</pre></blockquote>
This leads to a time complexity of O(N<sup>2</sup>).
<p> 


</p><p class="technote">
<b>Self-check</b> To test your analysis of arrays and linked lists, fill in the table below.
</p><p>
Compare the complexity of performing the following operations on Arrays and Linked lists. What search 
method would you use?
What's the best/worst case? What is the <i>average</i> number of accesses? Assume each value has equal 
probability of being in the array/list. Also,
after the operation, the container must still be a valid array/list type.
</p><p>

<!--
Unsorted list
<ol>
<li>Adding/Inserting an item
<li>Finding a particular item
<li>Finding the <i>i</i>th element
<li>Finding the maximum item
<li>Deleting a particular item
</ol>
Sorted list
<ol>
<li>Adding an item
<li>Finding a particular item
<li>Finding the <i>i</i>th element
<li>Finding the maximum item
<li>Deleting a particular item
</ol>
-->

</p><p>
<table border="1" cellspacing="1" cellpadding="10">
<tbody><tr><th>Operation</th><th>Unsorted array</th><th>Sorted array</th><th>Unsorted linked list</th><th>Sorted linked list</th></tr>
<tr><td>Finding a particular item<br>(by value)</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>Finding the <i>i</i>th element</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>Finding the maximum item</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>Adding an item</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>Deleting a particular item<br>(by value)</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
</tbody></table>

</p><p>




<big><a href="http://azrael.digipen.edu/~mmead/www/Courses/CS280/Sorting-1.html">Sorting</a></big>
</p><p>

</p><p class="technote">
<b>Self-check</b> To test your analysis of the sort algorithms, fill in the table below.
</p><p>
<table border="1" cellspacing="1" cellpadding="10">
<tbody><tr><th>Sort</th><th>Least Comparisons</th><th>Least Exchanges</th><th>Most Comparisons</th><th>Most Exchanges</th></tr>
<tr><td>Bubble sort</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>Insertion sort</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>Selection sort</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<!--
<tr><td>Quicksort</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
-->
</tbody></table>
</p><p>

</p><hr>
<p>


</p><hr>
<p>


</p><h2>Real World<sup>TM</sup> Considerations</h2>

Although we can study algorithms in a vacuum and independent of outside influences, the 
ultimate goal
of algorithm analysis is to apply the results to real situations on real computers. Given that, 
there are times
when knowing the <i>worst-case asymptotic behavior</i> doesn't really help. Some cases are:

<ul>
<li>The program will only be used a few times.
</li><li>The size of the data is always small.
<!--
<li>The memory usage is too expensive.
<li>Hardware resources affect the algorithms performance significantly. (Think cache)
-->
</li><li>A complex algorithm may require too much maintenance from humans.
  <ul>
    <li>Sometimes an "almost" optimal algorithm is better than an optimal one.</li>
  </ul>
</li></ul>

Notes about the worst-case:
<ul>
<li>We study the worst-case performance because often times it is much harder to predict the
average-case performance. 
</li><li>This is because we can't make any assumptions about the distribution of the input data.
</li><li>There are situations when we can make assumptions of the input data.
</li><li>If we have insight into the data distribution, we can predict (and use) the average-case
analysis instead.
<ul>
  <li>Knowing the data distribution will help us pick the "better" algorithm.</li>
</ul>
</li></ul>

<!-- ************************************************************************************************ -->
<!-- ************************************************************************************************ -->
<hr>

<h2>Putting it together</h2>

Given what you now know about algorithms and their associated complexities at this point, 
what conclusions can you draw about the performances of the two algorithms in the graph below?

<p>
<img src="./Algorithm Analysis_files/GraphOfBigO.gif" width="607" height="289">
</p><p>
</p><h3>Formal definition of 0-Notation:</h3>

<i>f(n)</i> is <i>O(g(n))</i> if there exists two positive constants, <i>K</i> and <i>n<sub>0</sub></i>, 
such that <i>f(n) &lt;= K(g(n))</i> for all <i>n &gt;= n<sub>0</sub></i>.
<p>
<b>Stated another way:</b><br>
An algorithm's complexity is <i>O(g(n))</i> if there exists a constant factor <i>K</i> and
some input size <i>n<sub>0</sub></i> such that the time required by the algorithm with inputs
greater than <i>n<sub>0</sub></i> is always less than <i>K(g(n))</i>.
</p><p>
Also look at <b>Figure 2.5</b> on page 48 of the Sedgewick book.

</p><p>
</p><hr width="90%">
<p>

<b>Visually stated:</b>

</p><p>
<img src="./Algorithm Analysis_files/K(g(n))-2.gif">
</p><p>

Given the function: <i>f(n) = 2x<sup>2</sup> + 8x lg x + 100</i>, we have
some candidate functions for <i>g(n)</i>:

If <i>g(n) = x<sup>2</sup></i> then:

</p><ol>
<li><i>K = 10, K(g(n)) = 10x<sup>2</sup>, n<sub>0</sub> = 3.805</i>
</li><li><i>K = 4, K(g(n)) = 4x<sup>2</sup>, n<sub>0</sub> = 9.264</i>
</li><li><i>K = 3, K(g(n)) = 3x<sup>2</sup>, n<sub>0</sub> = 15.904</i>
</li><li><i>K = 2, K(g(n)) = 2x<sup>2</sup></i>, (no possible value for n<sub>0</sub>)
</li><li><i>K = 1, K(g(n)) = x<sup>2</sup></i>, (no possible value for n<sub>0</sub>)
</li></ol>

With <i>K = 2.1, K(g(n)) = 2.1x<sup>2</sup>, n<sub>0</sub> = 188</i> (approximate)
<p>
The take-away here is that all of the functions above <b><i>grow at the same rate</i></b> and
are in the same category. (<tt>N<sup>2</sup></tt> algorithms)
</p><p>
	
Notes
</p><ul>
<li>Generally speaking, you should characterize the running time as accurately as possible. 
	For example, although this is correct, it's not as accurate as it could be:
<blockquote><pre>3n<sup>2</sup> is O(5n<sup>2</sup> + 7n + 30)
</pre></blockquote>
</li><li>Don't include constants or lower-order terms in the notation. This is the proper way:
<blockquote><pre>3n<sup>2</sup> is O(n<sup>2</sup>)
</pre></blockquote>
</li></ul>
	
<hr>
<p>
<b>Self-test</b>: During the execution of this function, how many statements are evaluated
at runtime (<i>f(n)</i>, where <i>n</i> is the size of the array)? 
What is the worst-case time complexity of this function (<i>O(g(n))</i>)?
</p><p>

     </p><pre class="sourcecode"><code>
     <b>void</b> SelectionSort(<b>int</b> array[], <b>int</b> size)
     {
1.     <b>for</b> (<b>int</b> i = 0; i &lt; size; i++)
       {
2.       <b>int</b> pos = i;
3.       <b>for</b> (<b>int</b> j = i + 1; j &lt; size; j++)
4.         <b>if</b> (array[j] &lt; array[pos])
5.           pos = j;
6.       <b>int</b> temp = array[pos];
7.       array[pos] = array[i];
8.       array[i] = temp;
       }
     }
</code></pre>






<blockquote><pre></pre></blockquote>
<!-- ************************************************************************************************ -->
<!-- ************************************************************************************************ -->
<hr>

</body></html>